@inproceedings{inproceedings,
author = {Neri, Ferrante and Weber, Matthieu and Caraffini, Fabio and Poikolainen, Ilpo},
year = {2012},
month = {09},
pages = {},
title = {Meta-Lamarckian Learning in Three Stage Optimal Memetic Exploration},
journal = {2012 12th UK Workshop on Computational Intelligence, UKCI 2012},
doi = {10.1109/UKCI.2012.6335770}
}


@Article{iasc.2022.020975,
AUTHOR = {Rahul Dubey, Jitendra Agrawal},
TITLE = {An Improved Genetic Algorithm for Automated Convolutional Neural Network Design},
JOURNAL = {Intelligent Automation \& Soft Computing},
VOLUME = {32},
YEAR = {2022},
NUMBER = {2},
PAGES = {747--763},
URL = {http://www.techscience.com/iasc/v32n2/45582},
ISSN = {2326-005X},
ABSTRACT = {Extracting the features from an image is a cumbersome task. Initially, this task was performed by domain experts through a process known as handcrafted feature design. A deep embedding technique known as convolutional neural networks (CNNs) later solved this problem by introducing the feature learning concept, through which the CNN is directly provided with images. This CNN then learns the features of the image, which are subsequently given as input to the further layers for an intended task like classification. CNNs have demonstrated astonishing performance in several practicable applications in the last few years. Nevertheless, the pursuance of CNNs primarily depends upon their architecture, which is handcrafted by domain expertise and type of investigated problem. On the other hand, for researchers who do not have proficiency in using CNNs, it has been very difficult to explore this topic in their problem statements. In this paper, we have come up with a rank and gradient descent-based optimized genetic algorithm to automatically find the architecture design of CNNs that is vigorously competent in exploring the best CNN architecture for maneuvering the tasks of image classification. In the proposed algorithm, there is no requirement for handcrafted pre- and post-processing, which implies that the algorithm is fully mechanized. The validation of the proposed algorithm on conventional benchmarked datasets has been done by comparing the run time of a graphics processing unit (GPU) throughout the training process and assessing the accuracy of various measures. The experimental results show that the proposed algorithm accomplishes better and more persistent ‘classification accuracy’ than the original genetic algorithm on the CIFAR datasets by using fifty percent less intensive computing resources for training the individual CNN and the entire population.},
DOI = {10.32604/iasc.2022.020975}
}

@article{DBLP:journals/corr/abs-1808-03818,
  author    = {Yanan Sun and
               Bing Xue and
               Mengjie Zhang and
               Gary G. Yen},
  title     = {Automatically Designing {CNN} Architectures Using Genetic Algorithm
               for Image Classification},
  journal   = {CoRR},
  volume    = {abs/1808.03818},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.03818},
  eprinttype = {arXiv},
  eprint    = {1808.03818},
  timestamp = {Tue, 31 Aug 2021 17:03:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-03818.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{GoogleNet,
  doi = {10.48550/ARXIV.1409.4842},
  
  url = {https://arxiv.org/abs/1409.4842},
  
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Going Deeper with Convolutions},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{VGG,
  doi = {10.48550/ARXIV.1409.1556},
  
  url = {https://arxiv.org/abs/1409.1556},
  
  author = {Simonyan, Karen and Zisserman, Andrew},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{PSO_CNN,
  author={Kim, Tae-Young and Cho, Sung-Bae},
  booktitle={2019 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Particle Swarm Optimization-based CNN-LSTM Networks for Forecasting Energy Consumption}, 
  year={2019},
  volume={},
  number={},
  pages={1510-1516},
  doi={10.1109/CEC.2019.8789968}}

@article{CIFAR10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@ARTICLE{NSGA2,
  author={Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={A fast and elitist multiobjective genetic algorithm: NSGA-II}, 
  year={2002},
  volume={6},
  number={2},
  pages={182-197},
  doi={10.1109/4235.996017}}

@INPROCEEDINGS{PSO,
  author={Kennedy, J. and Eberhart, R.},
  booktitle={Proceedings of ICNN'95 - International Conference on Neural Networks}, 
  title={Particle swarm optimization}, 
  year={1995},
  volume={4},
  number={},
  pages={1942-1948 vol.4},
  doi={10.1109/ICNN.1995.488968}}


@misc{ResNet,
  doi = {10.48550/ARXIV.1512.03385},
  
  url = {https://arxiv.org/abs/1512.03385},
  
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Residual Learning for Image Recognition},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@INPROCEEDINGS{ImageNet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@INPROCEEDINGS{1202255,
  author={Gudise, V.G. and Venayagamoorthy, G.K.},
  booktitle={Proceedings of the 2003 IEEE Swarm Intelligence Symposium. SIS'03 (Cat. No.03EX706)}, 
  title={Comparison of particle swarm optimization and backpropagation as training algorithms for neural networks}, 
  year={2003},
  volume={},
  number={},
  pages={110-117},
  doi={10.1109/SIS.2003.1202255}}


@article{DBLP:journals/corr/abs-1909-13354,
  author    = {Parsa Esfahanian and
               Mohammad Akhavan},
  title     = {{GACNN:} Training Deep Convolutional Neural Networks with Genetic
               Algorithm},
  journal   = {CoRR},
  volume    = {abs/1909.13354},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.13354},
  eprinttype = {arXiv},
  eprint    = {1909.13354},
  timestamp = {Wed, 02 Oct 2019 13:04:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-13354.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{GARDNER,
title = {Artificial neural networks (the multilayer perceptron)—a review of applications in the atmospheric sciences},
journal = {Atmospheric Environment},
volume = {32},
number = {14},
pages = {2627-2636},
year = {1998},
issn = {1352-2310},
doi = {https://doi.org/10.1016/S1352-2310(97)00447-0},
url = {https://www.sciencedirect.com/science/article/pii/S1352231097004470},
author = {M.W Gardner and S.R Dorling},
keywords = {Statistical modelling, neural network, backpropagation, artificial intelligence},
abstract = {Artificial neural networks are appearing as useful alternatives to traditional statistical modelling techniques in many scientific disciplines. This paper presents a general introduction and discussion of recent applications of the multilayer perceptron, one type of artificial neural network, in the atmospheric sciences.}
}

@inproceedings{AlexNet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}

@ARTICLE{Lecun,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}



  @article{DBLP:journals/corr/abs-1810-03522,
  author    = {Zhichao Lu and
               Ian Whalen and
               Vishnu Boddeti and
               Yashesh D. Dhebar and
               Kalyanmoy Deb and
               Erik D. Goodman and
               Wolfgang Banzhaf},
  title     = {{NSGA-NET:} {A} Multi-Objective Genetic Algorithm for Neural Architecture
               Search},
  journal   = {CoRR},
  volume    = {abs/1810.03522},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.03522},
  eprinttype = {arXiv},
  eprint    = {1810.03522},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-03522.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{10.5555/1623755.1623876,
author = {Montana, David J. and Davis, Lawrence},
title = {Training Feedforward Neural Networks Using Genetic Algorithms},
year = {1989},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Multilayered feedforward neural networks possess a number of properties which make them particularly suited to complex pattern classification problems. However, their application to some realworld problems has been hampered by the lack of a training algonthm which reliably finds a nearly globally optimal set of weights in a relatively short time. Genetic algorithms are a class of optimization procedures which are good at exploring a large and complex space in an intelligent way to find values close to the global optimum. Hence, they are well suited to the problem of training feedforward networks. In this paper, we describe a set of experiments performed on data from a sonar image classification problem. These experiments both 1) illustrate the improvements gained by using a genetic algorithm rather than backpropagation and 2) chronicle the evolution of the performance of the genetic algorithm as we added more and more domain-specific knowledge into it.},
booktitle = {Proceedings of the 11th International Joint Conference on Artificial Intelligence - Volume 1},
pages = {762–767},
numpages = {6},
location = {Detroit, Michigan},
series = {IJCAI'89}
}

@article{Deb1995SimulatedBC,
  title={Simulated Binary Crossover for Continuous Search Space},
  author={Kalyanmoy Deb and Ram Bhushan Agrawal},
  journal={Complex Syst.},
  year={1995},
  volume={9}
}



@incollection{Krasnogor_2012,
	doi = {10.1007/978-3-540-92910-9_29},
	year = 2012,
	publisher = {Springer Berlin Heidelberg},
	pages = {905--935},
	author = {Natalio Krasnogor},
	title = {Memetic Algorithms},
	booktitle = {Handbook of Natural Computing}
}

@article{miller1995genetic,
  title={Genetic algorithms, tournament selection, and the effects of noise},
  author={Miller, Brad L and Goldberg, David E and others},
  journal={Complex systems},
  volume={9},
  number={3},
  pages={193--212},
  year={1995},
  publisher={[Champaign, IL, USA: Complex Systems Publications, Inc., c1987-}
}

@inproceedings{deb1999niched,
  title={A niched-penalty approach for constraint handling in genetic algorithms},
  author={Deb, Kalyanmoy and Agrawal, Samir},
  booktitle={Artificial neural nets and genetic algorithms},
  pages={235--243},
  year={1999},
  organization={Springer}
}
@article{CERDA2016641,
title = {Optimization using the gradient and simplex methods},
journal = {Talanta},
volume = {148},
pages = {641-648},
year = {2016},
issn = {0039-9140},
doi = {https://doi.org/10.1016/j.talanta.2015.05.061},
url = {https://www.sciencedirect.com/science/article/pii/S0039914015300175},
author = {Víctor Cerdà and Juan Luis Cerdà and Abubakr M. Idris},
keywords = {Multivariate optimization, Simplex, Maximum slope, Gradient},
abstract = {Traditionally optimization of analytical methods has been conducted using a univariate method, varying each parameter one-by-one holding fixed the remaining. This means in many cases to reach only local minima and not get the real optimum. Among the various options for multivariate optimization, this paper highlights the gradient method, which involves the ability to perform the partial derivatives of a mathematical model, as well as the simplex method that does not require that condition. The advantages and disadvantages of those two multivariate optimization methods are discussed, indicating when they can be applied and the different forms that have been introduced. Different cases are described on the applications of these methods in analytical chemistry.}
}


@misc{regularization,
  doi = {10.48550/ARXIV.1710.10686},
  
  url = {https://arxiv.org/abs/1710.10686},
  
  author = {Kukačka, Jan and Golkov, Vladimir and Cremers, Daniel},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.6; I.5, 62M45},
  
  title = {Regularization for Deep Learning: A Taxonomy},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{NSGA,
author = {Srinivas, N. and Deb, Kalyan},
year = {1994},
month = {11},
pages = {},
title = {Multi-Objective function optimization using non-dominated sorting genetic algorithms},
volume = {2}
}

@article{fitch_1944, title={Warren S. McCulloch and Walter Pitts. A logical calculus of the ideas immanent in nervous activity. Bulletin of mathematical biophysics, vol. 5 (1943), pp. 115–133.}, volume={9}, DOI={10.2307/2268029}, number={2}, journal={Journal of Symbolic Logic}, publisher={Cambridge University Press}, author={Fitch, Frederic B.}, year={1944}, pages={49–50}}

@misc{adam,
  doi = {10.48550/ARXIV.1412.6980},
  
  url = {https://arxiv.org/abs/1412.6980},
  
  author = {Kingma, Diederik P. and Ba, Jimmy},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Adam: A Method for Stochastic Optimization},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{loussaief2018convolutional,
  title={Convolutional neural network hyper-parameters optimization based on genetic algorithms},
  author={Loussaief, Sehla and Abdelkrim, Afef},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={9},
  number={10},
  year={2018},
  publisher={Science and Information (SAI) Organization Limited}
}


@Inbook{Moscato2003,
author="Moscato, Pablo
and Cotta, Carlos",
editor="Glover, Fred
and Kochenberger, Gary A.",
title="A Gentle Introduction to Memetic Algorithms",
bookTitle="Handbook of Metaheuristics",
year="2003",
publisher="Springer US",
address="Boston, MA",
pages="105--144",
isbn="978-0-306-48056-0",
doi="10.1007/0-306-48056-5_5",
}